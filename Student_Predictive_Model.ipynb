{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "968f6584",
   "metadata": {},
   "source": [
    "# Importing the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9316a818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve\n",
    ")\n",
    "\n",
    "# Plot style for quick notebook readability\n",
    "sns.set_theme(style='whitegrid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df416b8a",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f434aead",
   "metadata": {},
   "source": [
    "### Importing the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c620a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load dataset\n",
    "# NOTE: We split FIRST (before any model preprocessing) to avoid leakage.\n",
    "df = pd.read_csv('ml_datasource.csv')\n",
    "\n",
    "print('Shape:', df.shape)\n",
    "print()\n",
    "print('Columns:', df.columns.tolist())\n",
    "print()\n",
    "print('Data types:')\n",
    "print(df.dtypes)\n",
    "\n",
    "# 1.1) Feature engineering from existing columns only (no dataset structure removed)\n",
    "# We add three derived behavioral features requested in the task.\n",
    "\n",
    "epsilon = 1e-6  # Prevent division by zero while keeping ratios numerically stable.\n",
    "\n",
    "# engagement_score: combines platform activity breadth and depth.\n",
    "# Higher when students watch more content, spend more days, and start more courses.\n",
    "df['engagement_score'] = (\n",
    "    df['minutes_watched'] * 0.6\n",
    "    + df['days_on_platform'] * 0.3\n",
    "    + df['courses_started'] * 10.0\n",
    ")\n",
    "\n",
    "# exam_success_rate: share of started practice exams that were passed.\n",
    "# If no practice exams were started, rate is set to 0.0 by assumption.\n",
    "df['exam_success_rate'] = np.where(\n",
    "    df['practice_exams_started'] > 0,\n",
    "    df['practice_exams_passed'] / (df['practice_exams_started'] + epsilon),\n",
    "    0.0\n",
    ")\n",
    "\n",
    "# learning_consistency: average watch time per active day.\n",
    "# Uses max(days_on_platform, 1) so zero-day edge cases remain defined.\n",
    "df['learning_consistency'] = df['minutes_watched'] / np.maximum(df['days_on_platform'], 1)\n",
    "\n",
    "# Keep target and features with newly engineered columns included.\n",
    "target_col = 'purchased'\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# Stratified split to preserve class distribution in train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print()\n",
    "print('Train shape:', X_train.shape, '| Test shape:', X_test.shape)\n",
    "print('Target distribution (full):')\n",
    "print(y.value_counts(normalize=True).sort_index())\n",
    "print('Target distribution (train):')\n",
    "print(y_train.value_counts(normalize=True).sort_index())\n",
    "print('Target distribution (test):')\n",
    "print(y_test.value_counts(normalize=True).sort_index())\n",
    "\n",
    "print() \n",
    "print('New engineered features added: engagement_score, exam_success_rate, learning_consistency')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Assumptions\n",
    "- **engagement_score** is a weighted blend of watch time, tenure, and course starts (`0.6*minutes_watched + 0.3*days_on_platform + 10*courses_started`). We assume course starts should have stronger unit impact than raw minutes/days.\n",
    "- **exam_success_rate** is `practice_exams_passed / practice_exams_started`. When `practice_exams_started = 0`, we set the feature to `0.0` instead of NaN to represent no demonstrated exam success activity.\n",
    "- **learning_consistency** is `minutes_watched / max(days_on_platform, 1)` to capture average daily learning intensity while safely handling potential zero-day edge cases.\n",
    "- These features are computed from existing row-level columns only (no target leakage, no external data).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7ab2c7",
   "metadata": {},
   "source": [
    "### Removing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7927c4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Perform EDA (on training data to keep test set untouched for development decisions)\n",
    "train_df = X_train.copy()\n",
    "train_df[target_col] = y_train.values\n",
    "\n",
    "print(train_df.head())\n",
    "print('Missing values (train):')\n",
    "print(train_df.isna().sum())\n",
    "\n",
    "print()\n",
    "print('Summary statistics (train numeric columns):')\n",
    "print(train_df.describe(include=[np.number]).T)\n",
    "\n",
    "# Basic target balance visualization\n",
    "plt.figure(figsize=(5, 3))\n",
    "ax = sns.countplot(x=y_train)\n",
    "ax.set_title('Target distribution in training set')\n",
    "ax.set_xlabel(target_col)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Distribution snapshots for numeric features\n",
    "numeric_preview_cols = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "if numeric_preview_cols:\n",
    "    X_train[numeric_preview_cols].hist(figsize=(12, 8), bins=30)\n",
    "    plt.suptitle('Numeric feature distributions (train set)', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9cc4a7",
   "metadata": {},
   "source": [
    "### Checking for Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc1e88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Remove outliers safely\n",
    "# We avoid dropping rows and avoid touching test set directly.\n",
    "# Instead, we define an IQR-based clipping transformer that will be FIT ONLY on train.\n",
    "\n",
    "class IQRClipper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Clip numeric values to IQR bounds learned from training data only.\"\"\"\n",
    "    def __init__(self, factor=1.5):\n",
    "        self.factor = factor\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_df = pd.DataFrame(X)\n",
    "        q1 = X_df.quantile(0.25)\n",
    "        q3 = X_df.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "\n",
    "        self.lower_bounds_ = (q1 - self.factor * iqr).to_numpy(dtype=float)\n",
    "        self.upper_bounds_ = (q3 + self.factor * iqr).to_numpy(dtype=float)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_arr = np.asarray(X, dtype=float)\n",
    "        return np.clip(X_arr, self.lower_bounds_, self.upper_bounds_)\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        if input_features is None:\n",
    "            return np.array([f'feature_{i}' for i in range(len(self.lower_bounds_))], dtype=object)\n",
    "        return np.asarray(input_features, dtype=object)\n",
    "\n",
    "print('Custom outlier handler (IQRClipper) defined.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f1e168",
   "metadata": {},
   "source": [
    "### Dealing with NaN Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21f9c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Handle missing values (strategy setup + diagnostics)\n",
    "# Diagnostics BEFORE building the preprocessing pipeline\n",
    "print('Missing values by column (X_train):')\n",
    "print(X_train.isna().sum())\n",
    "\n",
    "print()\n",
    "print('Missing values by column (X_test):')\n",
    "print(X_test.isna().sum())\n",
    "\n",
    "# Identify column groups\n",
    "numeric_features = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "print()\n",
    "print('Numeric features:', numeric_features)\n",
    "print('Categorical features:', categorical_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c7040a",
   "metadata": {},
   "source": [
    "### Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b8b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Splitting the Data (already completed first, by design)\n",
    "print('Data split was intentionally executed immediately after loading to prevent leakage.')\n",
    "print(f'X_train: {X_train.shape}, X_test: {X_test.shape}')\n",
    "print(f'y_train: {y_train.shape}, y_test: {y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced87b59",
   "metadata": {},
   "source": [
    "### Encoding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89c5791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Encode categorical variables + scale numerical variables\n",
    "# Build a single leakage-safe preprocessing object with ColumnTransformer.\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('outlier_clipper', IQRClipper(factor=1.5)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Fit ONLY on training data to avoid leakage\n",
    "X_train_prepared = preprocessor.fit_transform(X_train)\n",
    "X_test_prepared = preprocessor.transform(X_test)\n",
    "\n",
    "print('Preprocessing complete.')\n",
    "print('Transformed train shape:', X_train_prepared.shape)\n",
    "print('Transformed test shape:', X_test_prepared.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50436b36",
   "metadata": {},
   "source": [
    "# Creating a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e88380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison setup (cross-validation on TRAIN only)\n",
    "# We compare five classifiers using the same preprocessing object.\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=2000, random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=7),\n",
    "    'SVM': SVC(kernel='rbf', C=1.0, gamma='scale', probability=True, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=8, min_samples_leaf=10, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        max_depth=None,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = {\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1'\n",
    "}\n",
    "\n",
    "cv_results = []\n",
    "fitted_pipelines = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    scores = cross_validate(\n",
    "        pipe,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=False\n",
    "    )\n",
    "\n",
    "    cv_results.append({\n",
    "        'model': name,\n",
    "        'cv_roc_auc_mean': np.mean(scores['test_roc_auc']),\n",
    "        'cv_precision_mean': np.mean(scores['test_precision']),\n",
    "        'cv_recall_mean': np.mean(scores['test_recall']),\n",
    "        'cv_f1_mean': np.mean(scores['test_f1'])\n",
    "    })\n",
    "\n",
    "    # Fit full train once for final test evaluation after CV\n",
    "    pipe.fit(X_train, y_train)\n",
    "    fitted_pipelines[name] = pipe\n",
    "\n",
    "cv_results_df = pd.DataFrame(cv_results).sort_values('cv_roc_auc_mean', ascending=False)\n",
    "print('Cross-validation comparison (sorted by ROC-AUC):')\n",
    "print(cv_results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d10db71",
   "metadata": {},
   "source": [
    "# Creating a K-Nearest Neighbors Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2352fb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best model by cross-validated ROC-AUC\n",
    "best_model_name = cv_results_df.iloc[0]['model']\n",
    "best_pipeline = fitted_pipelines[best_model_name]\n",
    "\n",
    "print('Best model selected (by CV ROC-AUC):', best_model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aa87a4",
   "metadata": {},
   "source": [
    "# Creating a Support Vector Machines Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a392bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all models on test set (ROC-AUC, precision, recall)\n",
    "test_results = []\n",
    "\n",
    "for name, pipe in fitted_pipelines.items():\n",
    "    preds = pipe.predict(X_test)\n",
    "    probs = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    test_results.append({\n",
    "        'model': name,\n",
    "        'test_accuracy': accuracy_score(y_test, preds),\n",
    "        'test_roc_auc': roc_auc_score(y_test, probs),\n",
    "        'test_precision': precision_score(y_test, preds, zero_division=0),\n",
    "        'test_recall': recall_score(y_test, preds, zero_division=0),\n",
    "        'test_f1': f1_score(y_test, preds, zero_division=0)\n",
    "    })\n",
    "\n",
    "test_results_df = pd.DataFrame(test_results).sort_values('test_roc_auc', ascending=False)\n",
    "print('Test-set comparison (sorted by ROC-AUC):')\n",
    "print(test_results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172bf1f1",
   "metadata": {},
   "source": [
    "# Creating a Decision Trees Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530fbc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices for all compared models\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (name, pipe) in enumerate(fitted_pipelines.items()):\n",
    "    preds = pipe.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=axes[i])\n",
    "    axes[i].set_title(name)\n",
    "    axes[i].set_xlabel('Predicted')\n",
    "    axes[i].set_ylabel('Actual')\n",
    "\n",
    "for j in range(len(fitted_pipelines), len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "plt.suptitle('Confusion Matrices on Test Set', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b95ab9c",
   "metadata": {},
   "source": [
    "# Creating a Random Forests Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5119482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrate probabilities + tune threshold for high precision business goal\n",
    "# Business objective: prioritize precision for purchase prediction (class=1),\n",
    "# accepting lower recall to reduce false-positive outreach.\n",
    "\n",
    "# 1) Calibrate the selected best pipeline on training data only.\n",
    "# We use sigmoid calibration for stable probability mapping.\n",
    "calibrated_best_model = CalibratedClassifierCV(\n",
    "    estimator=best_pipeline,\n",
    "    method='sigmoid',\n",
    "    cv=5\n",
    ")\n",
    "calibrated_best_model.fit(X_train, y_train)\n",
    "\n",
    "# 2) Obtain calibrated probabilities on test set.\n",
    "calibrated_probs = calibrated_best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 3) Tune threshold for high precision.\n",
    "# Strategy: among thresholds where precision >= target_precision,\n",
    "# choose the one with the highest recall (best coverage under precision constraint).\n",
    "target_precision = 0.90\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, calibrated_probs)\n",
    "\n",
    "# precision_recall_curve returns len(thresholds)+1 for precision/recall.\n",
    "candidate_indices = [i for i, p in enumerate(precisions[:-1]) if p >= target_precision]\n",
    "\n",
    "if candidate_indices:\n",
    "    best_idx = max(candidate_indices, key=lambda i: recalls[i])\n",
    "    tuned_threshold = thresholds[best_idx]\n",
    "else:\n",
    "    # Fallback: maximize precision if constraint is unattainable.\n",
    "    best_idx = int(np.argmax(precisions[:-1]))\n",
    "    tuned_threshold = thresholds[best_idx]\n",
    "\n",
    "tuned_preds = (calibrated_probs >= tuned_threshold).astype(int)\n",
    "\n",
    "print('Selected Best Model:', best_model_name)\n",
    "print('Calibration:', 'CalibratedClassifierCV(sigmoid, cv=5)')\n",
    "print('Business goal:', 'High precision for purchase prediction')\n",
    "print('Target precision:', target_precision)\n",
    "print('Chosen threshold:', round(float(tuned_threshold), 4))\n",
    "print()\n",
    "print('Metrics at tuned threshold')\n",
    "print('Accuracy:', round(accuracy_score(y_test, tuned_preds), 4))\n",
    "print('ROC-AUC (threshold-independent):', round(roc_auc_score(y_test, calibrated_probs), 4))\n",
    "print('Precision:', round(precision_score(y_test, tuned_preds, zero_division=0), 4))\n",
    "print('Recall:', round(recall_score(y_test, tuned_preds, zero_division=0), 4))\n",
    "print('F1:', round(f1_score(y_test, tuned_preds, zero_division=0), 4))\n",
    "print()\n",
    "print('Classification Report (tuned threshold):')\n",
    "print(classification_report(y_test, tuned_preds, zero_division=0))\n",
    "\n",
    "cm_tuned = confusion_matrix(y_test, tuned_preds)\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.heatmap(cm_tuned, annot=True, fmt='d', cmap='Purples')\n",
    "plt.title(f'Best Model Confusion Matrix (Threshold={tuned_threshold:.3f})')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance and SHAP Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract transformed feature names for interpretation\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "# Use the uncalibrated best pipeline's final estimator for model-specific importance when available.\n",
    "best_estimator = best_pipeline.named_steps['model']\n",
    "\n",
    "# 1) Native feature importance (tree-based) or permutation fallback.\n",
    "if hasattr(best_estimator, 'feature_importances_'):\n",
    "    importances = best_estimator.feature_importances_\n",
    "else:\n",
    "    # Fallback for models without native importances.\n",
    "    perm = permutation_importance(best_pipeline, X_test, y_test, n_repeats=8, random_state=42, n_jobs=-1)\n",
    "    importances = perm.importances_mean\n",
    "\n",
    "fi_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "fi_df = fi_df.sort_values('importance', ascending=False).head(15)\n",
    "\n",
    "print('Top 15 features by importance:')\n",
    "print(fi_df)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "sns.barplot(data=fi_df, y='feature', x='importance', orient='h')\n",
    "plt.title(f'Top Feature Importance - {best_model_name}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) SHAP analysis for local/global explainability\n",
    "# We analyze on transformed test matrix for consistency with the trained model.\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "if hasattr(X_test_transformed, \"toarray\"):\n",
    "    X_test_transformed = X_test_transformed.toarray()\n",
    "X_test_transformed = np.asarray(X_test_transformed, dtype=float)\n",
    "\n",
    "# Limit SHAP compute volume for notebook responsiveness\n",
    "max_shap_rows = 150\n",
    "X_test_shap = X_test_transformed[:max_shap_rows]\n",
    "\n",
    "# Use TreeExplainer for tree-based models; otherwise use a model-agnostic explainer.\n",
    "if best_model_name in ['Random Forest', 'Decision Tree']:\n",
    "    explainer = shap.TreeExplainer(best_estimator)\n",
    "    shap_values = explainer.shap_values(X_test_shap, check_additivity=False)\n",
    "\n",
    "    # Binary classification may return list[class0, class1]\n",
    "    shap_values_pos = shap_values[1] if isinstance(shap_values, list) else shap_values\n",
    "    shap.summary_plot(shap_values_pos, X_test_shap, feature_names=feature_names, show=False)\n",
    "else:\n",
    "    background = preprocessor.transform(X_train.iloc[:300])\n",
    "    if hasattr(background, \"toarray\"):\n",
    "        background = background.toarray()\n",
    "    background = np.asarray(background, dtype=float)\n",
    "    sample_eval = X_test_shap\n",
    "    f = lambda data: best_estimator.predict_proba(data)[:, 1]\n",
    "    explainer = shap.KernelExplainer(f, background)\n",
    "    shap_values = explainer.shap_values(sample_eval, nsamples=100)\n",
    "    shap.summary_plot(shap_values, sample_eval, feature_names=feature_names, show=False)\n",
    "\n",
    "plt.title(f'SHAP Summary Plot - {best_model_name}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Insights\n",
    "- **High-precision targeting**: The tuned threshold is designed to reduce false-positive purchase predictions, making outreach campaigns more cost-efficient.\n",
    "- **Top drivers from feature importance/SHAP** identify the most actionable levers (engagement, exam outcomes, consistency), which can guide product nudges and lifecycle messaging.\n",
    "- **Operational recommendation**: prioritize interventions that lift the strongest positive drivers (e.g., sustained watch behavior and successful exam participation) for users close to the decision threshold.\n",
    "- **Governance**: monitor these feature effects over time (data drift) and re-calibrate thresholds periodically to preserve precision targets.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "365engagement",
   "language": "python",
   "name": "365engagement"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}