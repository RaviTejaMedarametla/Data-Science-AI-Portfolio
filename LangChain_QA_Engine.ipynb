{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05930fc5-89b1-4ff5-a889-b5086431bd28",
   "metadata": {},
   "source": [
    "# Create a Q&A Chatbot with LangChain Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424c50cf-21c2-4f02-83fd-e568379eef59",
   "metadata": {},
   "source": [
    "### Set the OpenAI API Key as an Environment Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8747c00-d9b7-4ac0-93d5-ef889fce6af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb206df-1a4d-4cb4-aa1b-70423a43a3ae",
   "metadata": {},
   "source": [
    "### Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829eb30a-8fec-4b81-bb41-056dec214c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import os\n",
    "\n",
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "\n",
    "from langchain_text_splitters import (MarkdownHeaderTextSplitter, \n",
    "                                      TokenTextSplitter)\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import (PromptTemplate,\n",
    "                                    HumanMessagePromptTemplate, \n",
    "                                    ChatPromptTemplate)\n",
    "from langchain_core.runnables import (RunnablePassthrough, \n",
    "                                      RunnableLambda, \n",
    "                                      chain)\n",
    "\n",
    "from langchain_openai import (ChatOpenAI, \n",
    "                              OpenAIEmbeddings)\n",
    "\n",
    "from langchain_chroma.vectorstores import Chroma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c084e32c-e209-4bc1-b4d0-d8e6a2b11963",
   "metadata": {},
   "source": [
    "### Load the Course Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb7f01a-5a9b-49d2-90b6-22c681ed33f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try loading a local transcript PDF. If missing, use a small fallback sample.\n",
    "pdf_path = Path('tableau_course_transcript.pdf')\n",
    "loader_pdf = PyPDFLoader(str(pdf_path)) if pdf_path.exists() else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8426085f-9154-405c-802f-3102aa429ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if loader_pdf is not None:\n",
    "    docs_list = loader_pdf.load()\n",
    "else:\n",
    "    sample_transcript = \"\"\"# Section: Calculations\n",
    "## Lecture: Adding a custom calculation\n",
    "In this lecture, we build GM% and explain why SUM is used for aggregation.\n",
    "### Notes\n",
    "Tableau computes calculations at different levels depending on dimensions in view.\n",
    "\n",
    "# Section: Visual Analytics\n",
    "## Lecture: Building charts\n",
    "We compare bar charts and line charts for trend analysis.\n",
    "\"\"\"\n",
    "    docs_list = [Document(page_content=sample_transcript, metadata={\"source\": \"fallback_sample\"})]\n",
    "\n",
    "print(f'Loaded documents: {len(docs_list)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bd8fe6-d49c-484f-a27a-13facb3a40da",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_list_concat = \"\\n\\n\".join(doc.page_content for doc in docs_list)\n",
    "print('Combined transcript character count:', len(string_list_concat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbdf062-cbf6-4c93-9120-6665989056d9",
   "metadata": {},
   "source": [
    "### Split the Course Transcript with MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e373b9-ad32-45a1-8c2c-33f7bbb2e956",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"section\"),\n",
    "    (\"##\", \"lecture\"),\n",
    "    (\"###\", \"topic\"),\n",
    "]\n",
    "\n",
    "md_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on,\n",
    "    strip_headers=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b157622-d5da-4eec-af0e-f6bf3e54e1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_list_md_split = md_splitter.split_text(string_list_concat)\n",
    "print('Markdown-split document count:', len(docs_list_md_split))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2d5cf9-71dc-4293-b11e-25cbe5577766",
   "metadata": {},
   "source": [
    "### Create a Chain to Correct the Course Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e47e9df-f7f9-45e1-88fb-7803af9aab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_list_split = [doc.page_content for doc in docs_list_md_split]\n",
    "print('Segments prepared for cleanup:', len(string_list_split))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e332a62-9d4a-4d00-9a07-99041b2ddd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_FORMATTING_S = '''Improve the following Tableau lecture transcript by:\n",
    "- Splitting the text into meaningful paragraphs\n",
    "- Correcting any misplaced punctuation\n",
    "- Fixing mistranscribed words (e.g., changing 'tableaux' to 'Tableau')\"\n",
    "'''\n",
    "\n",
    "PROMPT_TEMPLATE_FORMATTING_H = '''This is the transcript:\n",
    "{lecture_transcript}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecd79f3-4cca-4d11-9bb7-b7714b7dbb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_formatting_s = PromptTemplate.from_template(PROMPT_FORMATTING_S)\n",
    "prompt_template_formatting_h = HumanMessagePromptTemplate.from_template(PROMPT_TEMPLATE_FORMATTING_H)\n",
    "chat_prompt_template_formatting = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content='You are a transcript cleanup assistant.'),\n",
    "    prompt_template_formatting_h,\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538c92fb-adea-425c-b40e-6aa2839077f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional LLM model (kept optional so notebook works without API credentials)\n",
    "chat = ChatOpenAI(model='gpt-4o-mini', temperature=0) if loader_pdf is not None else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af89457-8698-4e60-8de0-24cd55a0555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_output_parser = StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79906ac0-08e2-48d5-bf34-ce80960caee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For deterministic local execution, we use a regex-based cleanup function.\n",
    "# (If desired, this can be replaced by an LLM chain using `chat_prompt_template_formatting | chat | str_output_parser`.)\n",
    "chain_formatting = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fc1a0e-92e9-43f5-ac5a-8d813e783937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_transcript(text: str) -> str:\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = text.replace('tableaux', 'Tableau').replace('tableau', 'Tableau')\n",
    "    text = re.sub(r'\\s+([,.!?;:])', r'\\1', text)\n",
    "    return text\n",
    "\n",
    "string_list_formatted = [cleanup_transcript(t) for t in string_list_split]\n",
    "print('Formatted transcript segments:', len(string_list_formatted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0c01db-4683-4b81-baa8-e1676bfc3c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override docs_list_md_split so each Document stores cleaned transcript text.\n",
    "for doc, cleaned_text in zip(docs_list_md_split, string_list_formatted):\n",
    "    doc.page_content = cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4e8ee8-8e0b-46f7-9b9c-7f90699aa6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sample cleaned segment:')\n",
    "print(docs_list_md_split[0].page_content[:300] if docs_list_md_split else 'No segments available')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8dc5aa-cb78-414a-8b41-c60a5d74bc3e",
   "metadata": {},
   "source": [
    "### Split the Lectures with TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbe0b3d-f78a-4b78-89c3-7a6ac09ffef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_splitter = TokenTextSplitter(\n",
    "    chunk_size=350,\n",
    "    chunk_overlap=50,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95238c0d-3d62-425f-93a9-10443913ad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_list_tokens_split = token_splitter.split_documents(docs_list_md_split)\n",
    "print('Token-split chunk count:', len(docs_list_tokens_split))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0886d56-6d15-4e15-850f-e7e12b8b26a1",
   "metadata": {},
   "source": [
    "### Create Embeddings, Vector Store, and Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249f1585-2281-4f20-a0d9-cf90934d906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key_present = bool(os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "if openai_api_key_present:\n",
    "    embedding = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "else:\n",
    "    embedding = None\n",
    "\n",
    "print('Embedding initialized:', embedding is not None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdeb49d-94a2-403f-897d-544c05474195",
   "metadata": {},
   "outputs": [],
   "source": [
    "if embedding is not None:\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=docs_list_tokens_split,\n",
    "        embedding=embedding,\n",
    "        collection_name='tableau_qa_collection',\n",
    "    )\n",
    "else:\n",
    "    vectorstore = None\n",
    "\n",
    "print('Vector store initialized:', vectorstore is not None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3cfdf2-9d32-423f-af0b-fce347136d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if vectorstore is not None:\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={'k': 4})\n",
    "else:\n",
    "    retriever = None\n",
    "\n",
    "print('Retriever initialized:', retriever is not None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d10e4ac-b6ed-4d7b-9512-33db50f4f49d",
   "metadata": {},
   "source": [
    "### Create Prompts and Prompt Templates for the Q&A Chatbot Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1833588-4edc-4a10-bde4-81e889708834",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_CREATING_QUESTION = \"\"\"Lecture: {question_lecture}\n",
    "Title: {question_title}\n",
    "Body: {question_body}\"\"\"\n",
    "\n",
    "PROMPT_RETRIEVING_S = \"\"\"You are a helpful teaching assistant for a Tableau course.\n",
    "You will receive a student question and supporting context passages.\n",
    "\n",
    "Rules:\n",
    "1) Answer ONLY using the supplied context.\n",
    "2) If context is insufficient, say exactly: \"I don't have enough context to answer confidently.\"\n",
    "3) Add a short \"Citations\" section at the end.\n",
    "4) Each citation must use this format:\n",
    "   - [Section: <section>, Lecture: <lecture>]\n",
    "5) Do not invent citations.\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_TEMPLATE_RETRIEVING_H = \"\"\"Question:\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\"\"\"\n",
    "\n",
    "prompt_creating_question = PromptTemplate.from_template(PROMPT_CREATING_QUESTION)\n",
    "prompt_retrieving_s = PromptTemplate.from_template(PROMPT_RETRIEVING_S)\n",
    "prompt_template_retrieving_h = HumanMessagePromptTemplate.from_template(PROMPT_TEMPLATE_RETRIEVING_H)\n",
    "\n",
    "chat_prompt_template_retrieving = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=PROMPT_RETRIEVING_S),\n",
    "    prompt_template_retrieving_h,\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf46c96-bd27-4868-a943-4338fa3e72fb",
   "metadata": {},
   "source": [
    "### Create the First Version of the Q&A Chatbot Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7151feb-4107-4f7a-bc97-be31262ed7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if openai_api_key_present and retriever is not None:\n",
    "    llm_for_qa = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
    "\n",
    "    chain_retrieving = (\n",
    "        {\n",
    "            'question': prompt_creating_question,\n",
    "            'context': retriever | RunnableLambda(lambda docs: '\\n\\n'.join(d.page_content for d in docs))\n",
    "        }\n",
    "        | chat_prompt_template_retrieving\n",
    "        | llm_for_qa\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "else:\n",
    "    chain_retrieving = None\n",
    "\n",
    "print('Retrieval chain initialized:', chain_retrieving is not None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02434124-5f37-4b3e-a8d4-21c702e2124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if chain_retrieving is not None:\n",
    "    result = chain_retrieving.invoke({\n",
    "        \"question_lecture\": \"Adding a custom calculation\",\n",
    "        \"question_title\": \"Why are we using SUM here? It's unclear to me.\",\n",
    "        \"question_body\": \"This question refers to calculating the GM%.\"\n",
    "    })\n",
    "else:\n",
    "    result = 'Chain not executed: configure OPENAI_API_KEY to run LLM retrieval.'\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1356e39-14cc-4cbc-b3a4-cc05a3f919f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6150053b-f05c-4d6f-b309-b9f471144c13",
   "metadata": {},
   "source": [
    "### Create a Runnable Function to Format the Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69a8cb6-f8d9-49e9-a0ef-6acb7c995534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_context(retrieved_docs):\n",
    "    \"\"\"Format retrieved docs with explicit citation metadata for grounded answers.\"\"\"\n",
    "    formatted_chunks = []\n",
    "\n",
    "    for i, doc in enumerate(retrieved_docs, start=1):\n",
    "        section = doc.metadata.get('section', 'Unknown Section')\n",
    "        lecture = doc.metadata.get('lecture', 'Unknown Lecture')\n",
    "        content = doc.page_content.strip()\n",
    "\n",
    "        formatted_chunks.append(\n",
    "            f\"[{i}] Section: {section} | Lecture: {lecture}\\n{content}\"\n",
    "        )\n",
    "\n",
    "    return '\\n\\n'.join(formatted_chunks)\n",
    "\n",
    "\n",
    "def extract_citations(answer_text: str):\n",
    "    pattern = r\"\\[Section:\\s*(.*?),\\s*Lecture:\\s*(.*?)\\]\"\n",
    "    return [(s.strip(), l.strip()) for s, l in re.findall(pattern, answer_text)]\n",
    "\n",
    "\n",
    "def validate_citations(citations, retrieved_docs):\n",
    "    allowed = {\n",
    "        (\n",
    "            str(doc.metadata.get('section', 'Unknown Section')).strip(),\n",
    "            str(doc.metadata.get('lecture', 'Unknown Lecture')).strip(),\n",
    "        )\n",
    "        for doc in retrieved_docs\n",
    "    }\n",
    "    if not citations:\n",
    "        return 0.0, []\n",
    "\n",
    "    valid = [c for c in citations if c in allowed]\n",
    "    ratio = len(valid) / len(citations)\n",
    "    invalid = [c for c in citations if c not in allowed]\n",
    "    return ratio, invalid\n",
    "\n",
    "\n",
    "def compute_confidence(answer_text: str, retrieved_docs, citation_valid_ratio: float):\n",
    "    if not retrieved_docs:\n",
    "        return 0.05\n",
    "\n",
    "    coverage = min(len(retrieved_docs) / 4.0, 1.0)\n",
    "    nonempty = 1.0 if answer_text and len(answer_text.strip()) > 20 else 0.0\n",
    "    score = 0.4 * coverage + 0.4 * citation_valid_ratio + 0.2 * nonempty\n",
    "    return round(float(score), 4)\n",
    "\n",
    "\n",
    "def answer_with_validation(question_payload: dict):\n",
    "    if retriever is None or llm_for_qa_improved is None:\n",
    "        return {\n",
    "            'answer': 'Retrieval/LLM not configured. Set OPENAI_API_KEY and initialize retriever.',\n",
    "            'confidence': 0.0,\n",
    "            'citations_valid': False,\n",
    "            'invalid_citations': [],\n",
    "            'citations': [],\n",
    "        }\n",
    "\n",
    "    question_text = prompt_creating_question.format(**question_payload)\n",
    "    retrieved_docs = retriever.invoke(question_text)\n",
    "\n",
    "    if not retrieved_docs:\n",
    "        fallback_answer = \"I don't have enough context to answer confidently.\"\n",
    "        return {\n",
    "            'answer': fallback_answer,\n",
    "            'confidence': 0.05,\n",
    "            'citations_valid': False,\n",
    "            'invalid_citations': [],\n",
    "            'citations': [],\n",
    "        }\n",
    "\n",
    "    context_text = format_context(retrieved_docs)\n",
    "\n",
    "    answer_text = (\n",
    "        chat_prompt_template_retrieving\n",
    "        | llm_for_qa_improved\n",
    "        | StrOutputParser()\n",
    "    ).invoke({'question': question_text, 'context': context_text})\n",
    "\n",
    "    citations = extract_citations(answer_text)\n",
    "    citation_valid_ratio, invalid = validate_citations(citations, retrieved_docs)\n",
    "    confidence = compute_confidence(answer_text, retrieved_docs, citation_valid_ratio)\n",
    "\n",
    "    if citation_valid_ratio == 0.0:\n",
    "        answer_text += \"\\n\\nCitations:\\n- [Section: Unknown Section, Lecture: Unknown Lecture]\"\n",
    "\n",
    "    return {\n",
    "        'answer': answer_text,\n",
    "        'confidence': confidence,\n",
    "        'citations_valid': citation_valid_ratio > 0,\n",
    "        'invalid_citations': invalid,\n",
    "        'citations': citations,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fbad37-bae4-49be-9d59-842b07618427",
   "metadata": {},
   "outputs": [],
   "source": [
    "if openai_api_key_present and retriever is not None:\n",
    "    llm_for_qa_improved = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
    "else:\n",
    "    llm_for_qa_improved = None\n",
    "\n",
    "# Retained variable name for notebook continuity\n",
    "chain_retrieving_improved = llm_for_qa_improved\n",
    "print('Improved retrieval backend initialized:', llm_for_qa_improved is not None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4495528d-bc83-44c4-a0c6-a673563cb5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_payload = {\n",
    "    \"question_lecture\": \"Adding a custom calculation\",\n",
    "    \"question_title\": \"Why are we using SUM here? It's unclear to me.\",\n",
    "    \"question_body\": \"This question refers to calculating the GM%.\"\n",
    "}\n",
    "\n",
    "result_improved = answer_with_validation(question_payload)\n",
    "result_improved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2fcd07-2fdd-4d82-8210-d6580f21b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_improved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3033f395-8cfc-404c-a2f7-e07c023f04d5",
   "metadata": {},
   "source": [
    "### Stream the Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8381358c-d8aa-4ccd-8aab-33576ac78ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if openai_api_key_present and retriever is not None and llm_for_qa_improved is not None:\n",
    "    result_streamed = (\n",
    "        chat_prompt_template_retrieving\n",
    "        | llm_for_qa_improved\n",
    "        | StrOutputParser()\n",
    "    ).stream({\n",
    "        'question': prompt_creating_question.format(\n",
    "            question_lecture='Adding a custom calculation',\n",
    "            question_title=\"Why are we using SUM here? It's unclear to me.\",\n",
    "            question_body='This question refers to calculating the GM%.'\n",
    "        ),\n",
    "        'context': format_context(retriever.invoke('Adding a custom calculation GM% SUM')),\n",
    "    })\n",
    "else:\n",
    "    result_streamed = []\n",
    "\n",
    "print('Streaming object prepared:', result_streamed is not None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e25ec6-4ca1-4d11-9bdb-a4e2453e4c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a for-loop to stream the response\n",
    "for chunk in result_streamed:\n",
    "    print(chunk, end='', flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df39b05c-00e5-40da-ac9e-53de17334b42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc848ace-bee5-45e0-a6f1-00c2e6ce7a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513a2594-aa62-4242-b403-452e848427d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494540aa-6ccc-471c-86b7-44a602f36938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7b2d26-4b3c-4a0c-b4a1-52e3fb84739b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env_project",
   "language": "python",
   "name": "langchain_env_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}